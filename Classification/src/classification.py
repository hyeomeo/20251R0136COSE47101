# -*- coding: utf-8 -*-
"""classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GewNq8b6bBQjQPhySFWV8VGgSgNnCPgD
"""

# ÏòàÏ∏°Î™®Îç∏

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report,
    mean_absolute_error, mean_squared_error, r2_score
)
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
df = pd.read_csv("preprocessed_with_cluster_ALL.csv")

# Drop REGION column
if "REGION" in df.columns:
    df = df.drop(columns=["REGION"])

# Drop rows with key missing values
df = df.dropna(subset=[
    "DGSTFN", "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "MVMN_NM",
    "REVISIT_INTENTION", "RCMDTN_INTENTION", "RELATION_TYPE",
    "VISIT_AREA_TYPE_CD"
])

# Create binary classification target
df["label"] = (df["DGSTFN"] >= 4.0).astype(int)


# ---------------------- Classification(Base) ---------------------- #
X_clf = df[[
    "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "REVISIT_INTENTION", "RCMDTN_INTENTION",
    "TRAVEL_STATUS_ACCOMPANY", "RELATION_TYPE", "MVMN_NM", "GENDER", "AGE_GRP", "VISIT_AREA_TYPE_CD"
]]
y_clf = df["label"]

cat_features_clf = [
    "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "TRAVEL_STATUS_ACCOMPANY",
    "RELATION_TYPE", "MVMN_NM", "GENDER", "AGE_GRP", "VISIT_AREA_TYPE_CD"
]

clf_preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features_clf)
], remainder="passthrough")

clf_pipeline = Pipeline([
    ("preprocessor", clf_preprocessor),
    ("classifier", LogisticRegression(max_iter=1000, class_weight="balanced"))
])

Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_clf, y_clf, test_size=0.3, random_state=42, stratify=y_clf)
clf_pipeline.fit(Xc_train, yc_train)
yc_pred = clf_pipeline.predict(Xc_test)

print("\nüìä Logistic Regression Report")
print(pd.DataFrame(classification_report(yc_test, yc_pred, output_dict=True)).transpose())
print("‚úÖ Accuracy:", accuracy_score(yc_test, yc_pred))
print("üß© Confusion Matrix:\n", confusion_matrix(yc_test, yc_pred))


# ---------------------- Random Forest Regression ---------------------- #
X_reg = df.drop(columns=[
    "DGSTFN", "label", "TRAVELER_ID", "TRAVEL_ID",
    "TRAVEL_START_YMD", "TRAVEL_END_YMD", "CLUSTER"
])
y_reg = df["DGSTFN"]

cat_features_reg = [
    "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "TRAVEL_STATUS_ACCOMPANY",
    "RELATION_TYPE", "MVMN_NM", "GENDER", "AGE_GRP", "VISIT_AREA_TYPE_CD"
]

reg_preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features_reg)
], remainder="passthrough")

reg_pipeline = Pipeline([
    ("preprocessor", reg_preprocessor),
    ("regressor", RandomForestRegressor(random_state=42))
])

Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)
reg_pipeline.fit(Xr_train, yr_train)
yr_pred = reg_pipeline.predict(Xr_test)

print("\nüìä Random Forest Regressor (Full Model)")
print("‚úÖ MAE:", round(mean_absolute_error(yr_test, yr_pred), 4))
print("‚úÖ MSE:", round(mean_squared_error(yr_test, yr_pred), 4))
print("‚úÖ R¬≤:", round(r2_score(yr_test, yr_pred), 4))


# ---------------------- Feature Importance ---------------------- #
rf_model = reg_pipeline.named_steps["regressor"]
feat_names = reg_pipeline.named_steps["preprocessor"].get_feature_names_out()
feat_importance = pd.DataFrame({"Feature": feat_names, "Importance": rf_model.feature_importances_})
feat_sorted = feat_importance.sort_values(by="Importance", ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feat_sorted.head(15), x="Importance", y="Feature")
plt.title("Top 15 Feature Importances (RandomForest)")
plt.tight_layout()
plt.savefig("feature_importance_rf.png")

# ---------------------- ÌÅ¥Îü¨Ïä§ÌÑ∞ Î≥Ñ Regression ---------------------- #
print("\nüìä Cluster-wise RF Regression by Gender and Age Group")
group_results = []

for (gender, age), group_df in df.groupby(["GENDER", "AGE_GRP"]):
    for cl in sorted(group_df["CLUSTER"].unique()):
        sub_df = group_df[group_df["CLUSTER"] == cl]
        if len(sub_df) < 30:
            continue

        X = sub_df.drop(columns=[
            "DGSTFN", "label", "TRAVELER_ID", "TRAVEL_ID",
            "TRAVEL_START_YMD", "TRAVEL_END_YMD"
        ])
        y = sub_df["DGSTFN"]
        X_enc = pd.get_dummies(X)

        X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.3, random_state=42)
        model = RandomForestRegressor(random_state=42)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        group_results.append({
            "GENDER": gender,
            "AGE_GRP": age,
            "CLUSTER": cl,
            "MAE": mean_absolute_error(y_test, y_pred),
            "MSE": mean_squared_error(y_test, y_pred),
            "R2": r2_score(y_test, y_pred)
        })

cluster_group_df = pd.DataFrame(group_results)
cluster_group_df.to_csv("clusterwise_group_rf_results.csv", index=False)
print("Saved: clusterwise_group_rf_results.csv")