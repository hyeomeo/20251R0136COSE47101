# -*- coding: utf-8 -*-
"""í´ëŸ¬ìŠ¤í„° ë³„ í†µí•©ëª¨ë¸ ì„±ëŠ¥

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fcDByVpggBs3G7-hrdKZ3ElsLEWgZEik
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import warnings

warnings.filterwarnings("ignore")

# 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
df = pd.read_csv("preprocessed_with_cluster_ALL.csv")
df = df.drop(columns=["REGION"], errors="ignore")

df = df.dropna(subset=[
    "DGSTFN", "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "MVMN_NM",
    "REVISIT_INTENTION", "RCMDTN_INTENTION", "RELATION_TYPE",
    "VISIT_AREA_TYPE_CD"
])

# ë¼ë²¨ ì •ì˜: 0 = ë¶ˆë§Œì¡± (1~2ì ), 1 = ë³´í†µ (3~4ì ), 2 = ë§Œì¡± (5ì )
def map_label(score):
    if score == 5:
        return 2
    elif score in [3, 4]:
        return 1
    else:
        return 0

df["label_3cls"] = df["DGSTFN"].apply(map_label)

# ë³€ìˆ˜ ì„¤ì •
cat_features = [
    "VISIT_AREA_NM", "MAIN_TRAVEL_MONTH", "TRAVEL_STATUS_ACCOMPANY",
    "RELATION_TYPE", "MVMN_NM", "GENDER", "AGE_GRP", "VISIT_AREA_TYPE_CD"
]
num_features = [
    "TRAVEL_STYL_1", "TRAVEL_STYL_3", "TRAVEL_STYL_5",
    "TRAVEL_STYL_6", "TRAVEL_STYL_7", "TRAVEL_STYL_8"
]

X = df[cat_features + num_features]
y = df["label_3cls"]

# 2. í†µí•© ëª¨ë¸ í•™ìŠµ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42
)

preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features),
    ("num", "passthrough", num_features)
])

pipeline = ImbPipeline(steps=[
    ("preprocessor", preprocessor),
    ("smote", SMOTE(random_state=42)),
    ("classifier", RandomForestClassifier(
        class_weight={0: 3, 1: 1, 2: 1},
        random_state=42
    ))
])

pipeline.fit(X_train, y_train)

# 3. ê° í´ëŸ¬ìŠ¤í„°ë³„ë¡œ í†µí•© ëª¨ë¸ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€
cluster_results = []

for (gender, age), group_df in df.groupby(["GENDER", "AGE_GRP"]):
    if len(group_df) < 500:
        continue  # ë„ˆë¬´ ì ì€ ë°ì´í„°ëŠ” ì œì™¸

    X_cluster = group_df[cat_features + num_features]
    y_cluster = group_df["label_3cls"]

    y_pred = pipeline.predict(X_cluster)
    report = classification_report(y_cluster, y_pred, output_dict=True)
    acc = accuracy_score(y_cluster, y_pred)

    cluster_results.append({
        "GENDER": gender,
        "AGE_GRP": age,
        "Samples": len(group_df),
        "Accuracy": round(acc, 4),
        "F1_ë¶ˆë§Œì¡±": round(report["0"]["f1-score"], 4),
        "F1_ë³´í†µ": round(report["1"]["f1-score"], 4),
        "F1_ë§Œì¡±": round(report["2"]["f1-score"], 4),
        "Macro_F1": round(report["macro avg"]["f1-score"], 4)
    })

# 4. ê²°ê³¼ ì •ë¦¬
results_df = pd.DataFrame(cluster_results)
results_df = results_df.sort_values("Macro_F1", ascending=False)

print("\nğŸ“Š [í´ëŸ¬ìŠ¤í„°ë³„ í†µí•© ëª¨ë¸ ì„±ëŠ¥]")
print(results_df)

# ì €ì¥ë„ ê°€ëŠ¥
results_df.to_csv("í†µí•©ëª¨ë¸_í´ëŸ¬ìŠ¤í„°ë³„_ì„±ëŠ¥ë¹„êµ.csv", index=False)